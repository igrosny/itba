{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "6a09d4fb-60c5-4f45-b844-8c788a50c543",
    "_uuid": "8e892e637f005dd61ec7dcb95865e52f3de2a77f"
   },
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "### Predict survival on the Titanic\n",
    "- Defining the problem statement\n",
    "- Collecting the data\n",
    "- Exploratory data analysis\n",
    "- Feature engineering\n",
    "- Modelling\n",
    "- Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4af5e83d-7fd8-4a61-bf26-9583cb6d3476",
    "_uuid": "65d04d276a8983f62a49261f6e94a02b281dbcc9"
   },
   "source": [
    "## 1. Defining the problem statement\n",
    "Complete the analysis of what sorts of people were likely to survive.  \n",
    "In particular, we ask you to apply the tools of machine learning to predict which passengers survived the Titanic tragedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"https://static1.squarespace.com/static/5006453fe4b09ef2252ba068/5095eabce4b06cb305058603/5095eabce4b02d37bef4c24c/1352002236895/100_anniversary_titanic_sinking_by_esai8mellows-d4xbme8.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3f529075-7f9b-40ff-a79a-f3a11a7d8cbe",
    "_uuid": "64ca0f815766e3e8074b0e04f53947930cb061aa"
   },
   "source": [
    "## 2. Collecting the data\n",
    "\n",
    "training data set and testing data set are given by Kaggle\n",
    "you can download from  \n",
    "my github [https://github.com/minsuk-heo/kaggle-titanic/tree/master](https://github.com/minsuk-heo/kaggle-titanic)  \n",
    "or you can download from kaggle directly [kaggle](https://www.kaggle.com/c/titanic/data)  \n",
    "\n",
    "### load train, test dataset using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e58a3f06-4c2a-4b87-90de-f8b09039fd4e",
    "_uuid": "46f0b12d7bf66712642e9a9b807f5ef398426b83",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('https://raw.githubusercontent.com/lab-ml-itba/Arboles-de-decision/master/data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "836a454f-17bc-41a2-be69-cd86c6f3b584",
    "_uuid": "1ed3ad39ead93977b8936d9c96e6f6f806a8f9b3"
   },
   "source": [
    "## 3. Exploratory data analysis\n",
    "Printing first 5 rows of the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "749a3d70-394c-4d2c-999a-4d0567e39232",
    "_uuid": "b9fdb3b19d7a8f30cd0bb69ae434e04121ecba93"
   },
   "outputs": [],
   "source": [
    "train.head(80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "- Survived: \t0 = No, 1 = Yes  \n",
    "- pclass: \tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd  \t\n",
    "- sibsp:\t# of siblings / spouses aboard the Titanic  \t\n",
    "- parch:\t# of parents / children aboard the Titanic  \t\n",
    "- ticket:\tTicket number\t\n",
    "- cabin:\tCabin number\t\n",
    "- embarked:\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5ebc1e0e-2b5a-4d92-98e0-defa019d4439",
    "_uuid": "1892fbb34b26d775d1c428fdb7b6254449286b28"
   },
   "source": [
    "**Total rows and columns**\n",
    "\n",
    "We can see that there are 891 rows and 12 columns in our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "ed1e7849-d1b6-490d-b86b-9ca71dfafc7d",
    "_uuid": "5a641beccf0e555dfd7b9a53a17188ea6edef95b"
   },
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "418b8a69-f2aa-442d-8f45-fa8887190938",
    "_uuid": "4ee2591110660a4a16b3da7a7530f0945e121b46"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "abc3c4fc-6419-405f-927a-4214d2c73eec",
    "_uuid": "622d4d4b2ba8f77cc537af97fc343d4cd6de26b2"
   },
   "source": [
    "We can see that *Age* value is missing for many rows. \n",
    "\n",
    "Out of 891 rows, the *Age* value is present only in 714 rows.\n",
    "\n",
    "Similarly, *Cabin* values are also missing in many rows. Only 204 out of 891 rows have *Cabin* values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "0663e2bb-dc27-4187-94b1-ff4ff78b68bc",
    "_uuid": "3bf74de7f2483d622e41608f6017f2945639e4df"
   },
   "outputs": [],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "176aa52d-fde8-42e6-a3ee-db31f8b0ca49",
    "_uuid": "b48a9feff6004d783960aa1b32fdfde902d87e21"
   },
   "source": [
    "There are 177 rows with missing *Age*, 687 rows with missing *Cabin* and 2 rows with missing *Embarked* information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c8553d48-c5e0-4947-bd13-1b38509c850c",
    "_uuid": "1a28e607e9ed63cefe0f35a4e4d72f2f36299323"
   },
   "source": [
    "### import python lib for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1d8a6d2-c22d-435c-8c98-973e8f41b138",
    "_uuid": "26411c710f69b29939c815d5f5ab01d9177df7d0",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set() # setting seaborn default for plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar Chart for Categorical Features\n",
    "- Pclass\n",
    "- Sex\n",
    "- SibSp ( # of siblings and spouse)\n",
    "- Parch ( # of parents and children)\n",
    "- Embarked\n",
    "- Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bar_chart(feature):\n",
    "    survived = train[train['Survived']==1][feature].value_counts()\n",
    "    dead = train[train['Survived']==0][feature].value_counts()\n",
    "    df = pd.DataFrame([survived,dead])\n",
    "    df.index = ['Survived','Dead']\n",
    "    df.plot(kind='bar',stacked=True, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar un gráfico de barras para para la variable \"Pchart\"\n",
    "#### Código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2)  \n",
    "¿Qué clase sobrevivió mas?\n",
    "\n",
    "3)\n",
    "¿Qué clase falleció mas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar un gráfico de barras para la variable \"SibSp\"\n",
    "### Código aquí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Seleccione las verdaderas:\n",
    "\n",
    "Las personas pertenecientes a familias numerosas en general fallecieron  \n",
    "Las personas solas en general fallecieron   \n",
    "Las personas solas en general sobrevivieron   \n",
    "Las personas pertenecientes a familias numerosas en general Sobrevivieron   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Parch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chart confirms **a person aboarded with more than 2 parents or children** more likely survived  \n",
    "The Chart confirms ** a person aboarded alone** more likely dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Embarked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chart confirms **a person aboarded from C** slightly more likely survived  \n",
    "The Chart confirms **a person aboarded from Q** more likely dead  \n",
    "The Chart confirms **a person aboarded from S** more likely dead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "810cd964-24eb-44fb-9e7b-18bbddd4900f",
    "_uuid": "fd86ccdf2d1248b79c68365444e96e46a50f3f5a"
   },
   "source": [
    "## 4. Feature engineering\n",
    "\n",
    "Feature engineering is the process of using domain knowledge of the data  \n",
    "to create features (**feature vectors**) that make machine learning algorithms work.  \n",
    "\n",
    "feature vector is an n-dimensional vector of numerical features that represent some object.  \n",
    "Many algorithms in machine learning require a numerical representation of objects,  \n",
    "since such representations facilitate processing and statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 how titanic sank?\n",
    "sank from the bow of the ship where third class rooms located  \n",
    "conclusion, Pclass is key feature for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url= \"https://static1.squarespace.com/static/5006453fe4b09ef2252ba068/t/5090b249e4b047ba54dfd258/1351660113175/TItanic-Survival-Infographic.jpg?format=1500w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Se puede utilizar para obtener el título de una persona: Mr\n",
    "train_test_data = [train] # combining train and test dataset\n",
    "\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escribir una línea de código que muestre cuántas veces apareció cada título (value_counts)\n",
    "train['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Cuantas veces apareció:\n",
    "    \n",
    "Mr:    \n",
    "Miss   \n",
    "Mrs    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Title map\n",
    "Mr : 0  \n",
    "Miss : 1  \n",
    "Mrs: 2  \n",
    "Others: 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n",
    "                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n",
    "                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\n",
    "for dataset in train_test_data:\n",
    "    dataset['Title'] = dataset['Title'].map(title_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Borrar la columna Name del dataset\n",
    "train.drop('Name', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Sex\n",
    "\n",
    "male: 0\n",
    "female: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sex_mapping = {\"male\": 0, \"female\": 1}\n",
    "for dataset in train_test_data:\n",
    "    dataset['Sex'] = dataset['Sex'].map(sex_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Sex')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.1 some age is missing\n",
    "\n",
    "Como algunas edades no figuran, hay que hacer data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Esta es la línea que se utiliza para hacer la imputación de la edad\n",
    "train[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) La imputación de la edad se hace según:\n",
    "La media de la columna.  \n",
    "La media de la columna condicionada por el título de la persona.  \n",
    "La mediana de la columna.  \n",
    "La mediana de la columna condicionada por el título de la persona.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(30)\n",
    "train.groupby(\"Title\")[\"Age\"].transform(\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    " \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(20, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(30, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(40, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(40, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Age',shade= True)\n",
    "facet.set(xlim=(0, train['Age'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.4.2 Binning\n",
    "\n",
    "\n",
    "Se convierte la edad numérica en variables categóricas.\n",
    "\n",
    "feature vector map:  \n",
    "child: 0  \n",
    "young: 1  \n",
    "adult: 2  \n",
    "mid-age: 3  \n",
    "senior: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0,\n",
    "    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1,\n",
    "    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2,\n",
    "    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3,\n",
    "    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_chart('Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 filling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\n",
    "Pclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\n",
    "Pclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\n",
    "df = pd.DataFrame([Pclass1, Pclass2, Pclass3])\n",
    "df.index = ['1st class','2nd class', '3rd class']\n",
    "df.plot(kind='bar',stacked=True, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) En base al gráfico anterior, con qué criterio rellenaría el puerto de embarque?\n",
    "\n",
    "S para todas las clases\n",
    "C para primera clase, S para el resto  \n",
    "Q para tercera clase, S para el resto  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].fillna('S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\n",
    "for dataset in train_test_data:\n",
    "    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Fare\n",
    "\n",
    "Rellenar la tarifa con la mediana de la tarifa condicionada por cada clase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing Fare with median fare for each Pclass\n",
    "# Escribir el código acá\n",
    "\n",
    "train.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    " \n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'Fare',shade= True)\n",
    "facet.set(xlim=(0, train['Fare'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0,\n",
    "    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1,\n",
    "    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2,\n",
    "    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Cabin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for dataset in train_test_data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].str[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\n",
    "Pclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\n",
    "Pclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\n",
    "df = pd.DataFrame([Pclass1, Pclass2, Pclass3])\n",
    "df.index = ['1st class','2nd class', '3rd class']\n",
    "df.plot(kind='bar',stacked=True, figsize=(10,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\n",
    "for dataset in train_test_data:\n",
    "    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fill missing Cabin with median Cabin for each Pclass\n",
    "train[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 FamilySize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\n",
    "facet.map(sns.kdeplot,'FamilySize',shade= True)\n",
    "facet.set(xlim=(0, train['FamilySize'].max()))\n",
    "facet.add_legend()\n",
    "plt.xlim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\n",
    "for dataset in train_test_data:\n",
    "    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_drop = ['Ticket', 'SibSp', 'Parch']\n",
    "train = train.drop(features_drop, axis=1)\n",
    "train = train.drop(['PassengerId'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.drop('Survived', axis=1)\n",
    "target = train['Survived']\n",
    "\n",
    "train_data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing Classifier Modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Cross Validation (K-fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 13)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.3 Ramdom Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=13)\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.4 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GaussianNB()\n",
    "scoring = 'accuracy'\n",
    "score = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Score\n",
    "round(np.mean(score)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Realizar una búsqueda de hiperparámetros para un modelo con decision tree,Random Forest y Extra Tree. Informar el error de validación cruzada usando k-folding con k=5 para cada uno de los mejores modelos.\n",
    "\n",
    "Decision Tree:\n",
    "\n",
    "Random Forest:  \n",
    "\n",
    "ExtRa Tree:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "This notebook is created by learning from the following notebooks:\n",
    "\n",
    "- [Mukesh ChapagainTitanic Solution: A Beginner's Guide](https://www.kaggle.com/chapagain/titanic-solution-a-beginner-s-guide?scriptVersionId=1473689)\n",
    "- [How to score 0.8134 in Titanic Kaggle Challenge](http://ahmedbesbes.com/how-to-score-08134-in-titanic-kaggle-challenge.html)\n",
    "- [Titanic: factors to survive](https://olegleyz.github.io/titanic_factors.html)\n",
    "- [Titanic Survivors Dataset and Data Wrangling](http://www.codeastar.com/data-wrangling/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
